{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook downloads data and creates train, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "import langid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Download data from all used corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://object.pouta.csc.fi/OPUS-CCMatrix/v1/moses/ar-en.txt.zip -P ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip -o ../data/raw/ar-en.txt.zip -d ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/raw/ar-en.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-07 15:53:03--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/moses/ar-en.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1014474587 (967M) [application/zip]\n",
      "Saving to: ‘../data/ar-en.txt.zip’\n",
      "\n",
      "ar-en.txt.zip       100%[===================>] 967,48M  27,3MB/s    in 42s     \n",
      "\n",
      "2022-05-07 15:53:45 (22,9 MB/s) - ‘../data/ar-en.txt.zip’ saved [1014474587/1014474587]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/moses/ar-en.txt.zip -P ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/ar-en.txt.zip\n",
      "  inflating: ../data/OpenSubtitles.ar-en.ar  \n",
      "  inflating: ../data/OpenSubtitles.ar-en.en  \n",
      "  inflating: ../data/OpenSubtitles.ar-en.ids  \n",
      "  inflating: ../data/README          \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ../data/raw/ar-en.txt.zip -d ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/raw/ar-en.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-07 15:54:03--  https://object.pouta.csc.fi/OPUS-News-Commentary/v16/moses/ar-en.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25988755 (25M) [application/zip]\n",
      "Saving to: ‘../data/ar-en.txt.zip’\n",
      "\n",
      "ar-en.txt.zip       100%[===================>]  24,78M  12,2MB/s    in 2,0s    \n",
      "\n",
      "2022-05-07 15:54:06 (12,2 MB/s) - ‘../data/ar-en.txt.zip’ saved [25988755/25988755]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://object.pouta.csc.fi/OPUS-News-Commentary/v16/moses/ar-en.txt.zip -P ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/ar-en.txt.zip\n",
      "  inflating: ../data/README          \n",
      "  inflating: ../data/LICENSE         \n",
      "  inflating: ../data/News-Commentary.ar-en.ar  \n",
      "  inflating: ../data/News-Commentary.ar-en.en  \n",
      "  inflating: ../data/News-Commentary.ar-en.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ../data/raw/ar-en.txt.zip -d ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/raw/ar-en.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-07 15:54:07--  https://object.pouta.csc.fi/OPUS-TED2013/v1.1/moses/ar-en.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12065234 (12M) [application/zip]\n",
      "Saving to: ‘../data/ar-en.txt.zip’\n",
      "\n",
      "ar-en.txt.zip       100%[===================>]  11,51M  12,6MB/s    in 0,9s    \n",
      "\n",
      "2022-05-07 15:54:08 (12,6 MB/s) - ‘../data/ar-en.txt.zip’ saved [12065234/12065234]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://object.pouta.csc.fi/OPUS-TED2013/v1.1/moses/ar-en.txt.zip -P ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/ar-en.txt.zip\n",
      "  inflating: ../data/TED2013.ar-en.ar  \n",
      "  inflating: ../data/TED2013.ar-en.en  \n",
      "  inflating: ../data/TED2013.ar-en.ids  \n",
      "  inflating: ../data/README          \n"
     ]
    }
   ],
   "source": [
    "!unzip -o ../data/raw/ar-en.txt.zip -d ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/raw/ar-en.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Help functions to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set how many sentences you want from each datset\n",
    "OPEN_SUBTITLES_SEN = 2_000_000\n",
    "CCMATRIX_SEN = 1_000_000\n",
    "NEWS_COMMENTARY_SEN = 83_296\n",
    "TED_SEN = np.inf # all sentences from this dataset\n",
    "MIN_SEN_LEN = 3\n",
    "MAX_SEN_LEN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Removing whitespaces that are not needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespaces(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello1 hi2 hi3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_extra_whitespaces(\"Hello1      hi2                      hi3\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Removing html tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Hi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(\"<br>Hello</br><p>Hi</p>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using langid to find not arabic and not english words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wrong_lang(text, expected_lang):\n",
    "    detected_lang = langid.classify(text)[0]\n",
    "    if detected_lang != expected_lang.lower():\n",
    "        return ''\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_ar(text):\n",
    "    return filter_wrong_lang(text, 'ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_en(text):\n",
    "    return filter_wrong_lang(text, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_wrong_lang('Język polski nie jest wykorzystywanym językiem w tym projekcie', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Although english is indeed used'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_wrong_lang('Although english is indeed used', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Filtering too short sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wrong_len(text):\n",
    "    splitted = len(text.split(' '))\n",
    "    if splitted < MIN_SEN_LEN or splitted > MAX_SEN_LEN:\n",
    "        return ''\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_wrong_len('Short sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not that short sentence anymore.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_wrong_len('Not that short sentence anymore.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_FUNCTIONS_EN = [remove_extra_whitespaces, remove_html_tags, filter_not_en, filter_wrong_len]\n",
    "PREPROCESSING_FUNCTIONS_AR = [remove_extra_whitespaces, remove_html_tags, filter_not_ar, filter_wrong_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(src_dir, ds_name, dst_dir, num_expected_sen, processing_fun_en, processing_fun_ar):\n",
    "    en_src_path = os.path.join(src_dir, f\"{ds_name}.ar-en.en\")\n",
    "    ar_src_path = os.path.join(src_dir, f\"{ds_name}.ar-en.ar\")\n",
    "    en_dst_path = os.path.join(dst_dir, f\"{ds_name}_processed_en.txt\")\n",
    "    ar_dst_path = os.path.join(dst_dir, f\"{ds_name}_processed_ar.txt\")\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    valid_lines = 0\n",
    "    \n",
    "    with open(en_src_path, \"r\", encoding=\"utf-8\") as src_file_en:\n",
    "        with open(ar_src_path, \"r\", encoding=\"utf-8\") as src_file_ar:\n",
    "            with open(en_dst_path, \"w\", encoding=\"utf-8\") as dst_file_en:\n",
    "                with open(ar_dst_path, \"w\", encoding=\"utf-8\") as dst_file_ar:\n",
    "                    for (en_line, ar_line) in zip(src_file_en, src_file_ar):\n",
    "                        processed_en_line = reduce(lambda a, f: f(a), processing_fun_en, en_line.rstrip())\n",
    "                        if processed_en_line:\n",
    "                            processed_ar_line = reduce(lambda a, f: f(a), processing_fun_ar, ar_line.rstrip())\n",
    "                            if processed_ar_line:\n",
    "                                dst_file_en.write(processed_en_line + \"\\n\")\n",
    "                                dst_file_ar.write(processed_ar_line + \"\\n\")\n",
    "                                valid_lines += 1\n",
    "                        \n",
    "                        if valid_lines >= num_expected_sen:\n",
    "                            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    src_dir=os.path.join(\"..\", \"data/raw\"),\n",
    "    ds_name=\"OpenSubtitles\",\n",
    "    dst_dir=os.path.join(\"..\", \"data/processed\"),\n",
    "    num_expected_sen=OPEN_SUBTITLES_SEN,\n",
    "    processing_fun_en=PREPROCESSING_FUNCTIONS_EN,\n",
    "    processing_fun_ar=PREPROCESSING_FUNCTIONS_AR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    src_dir=os.path.join(\"..\", \"data/raw\"),\n",
    "    ds_name=\"CCMatrix\",\n",
    "    dst_dir=os.path.join(\"..\", \"data/processed\"),\n",
    "    num_expected_sen=CCMATRIX_SEN,\n",
    "    processing_fun_en=PREPROCESSING_FUNCTIONS_EN,\n",
    "    processing_fun_ar=PREPROCESSING_FUNCTIONS_AR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    src_dir=os.path.join(\"..\", \"data/raw\"),\n",
    "    ds_name=\"News-Commentary\",\n",
    "    dst_dir=os.path.join(\"..\", \"data/processed\"),\n",
    "    num_expected_sen=NEWS_COMMENTARY_SEN,\n",
    "    processing_fun_en=PREPROCESSING_FUNCTIONS_EN,\n",
    "    processing_fun_ar=PREPROCESSING_FUNCTIONS_AR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    src_dir=os.path.join(\"..\", \"data/raw\"),\n",
    "    ds_name=\"TED2013\",\n",
    "    dst_dir=os.path.join(\"..\", \"data/processed\"),\n",
    "    num_expected_sen=TED_SEN,\n",
    "    processing_fun_en=PREPROCESSING_FUNCTIONS_EN,\n",
    "    processing_fun_ar=PREPROCESSING_FUNCTIONS_AR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Concatenate datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/processed/OpenSubtitles_processed_en.txt ../data/processed/CCMatrix_processed_en.txt ../data/processed/News-Commentary_processed_en.txt > ../data/processed/processed_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/processed/OpenSubtitles_processed_ar.txt ../data/processed/CCMatrix_processed_ar.txt ../data/processed/News-Commentary_processed_ar.txt > ../data/processed/processed_ar.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/processed/TED2013_processed_en.txt> ../data/processed/test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/processed/TED2013_processed_ar.txt> ../data/processed/test.ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split for train and val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_num = np.arange(0, CCMATRIX_SEN+NEWS_COMMENTARY_SEN+OPEN_SUBTITLES_SEN)\n",
    "val_nums = np.random.choice(lines_num, size=int(0.1*len(lines_num)), replace=False)\n",
    "with open('../data/processed/processed_en.txt', 'r', encoding=\"utf-8\") as en_file:\n",
    "    with open('../data/processed/processed_ar.txt', 'r', encoding=\"utf-8\") as ar_file:\n",
    "        with open('../data/processed/train.en', 'w', encoding=\"utf-8\") as train_en_file:\n",
    "            with open('../data/processed/train.ar', 'w', encoding=\"utf-8\") as train_ar_file:\n",
    "                with open('../data/processed/val.en', 'w', encoding=\"utf-8\") as val_en_file:\n",
    "                    with open('../data/processed/val.ar', 'w', encoding=\"utf-8\") as val_ar_file:\n",
    "                        for i, (en_line, ar_line) in enumerate(zip(en_file, ar_file)):\n",
    "                            if i in val_nums:\n",
    "                                val_en_file.write(en_line)\n",
    "                                val_ar_file.write(ar_line)\n",
    "                            else:\n",
    "                                train_en_file.write(en_line)\n",
    "                                train_ar_file.write(ar_line)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d381337f0636c01494a2b48813f34f25a0e66e43a6b7237f996b3ac56efc62d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('nlp-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
